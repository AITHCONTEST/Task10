{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e99a7ac-c7f2-4b01-a0d0-b1830998be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b666152a-cc06-4b92-8fa8-167b5b29ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from torch import nn\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import transformers\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# from trl import SFTTrainer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f112cc97-34a5-4e5d-b3ec-be5ffc84521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUS = \"<RUS>\"\n",
    "UDM = \"<UDM>\"\n",
    "KOMI = \"<KOMI>\"\n",
    "MHR = \"<MHR>\"\n",
    "EOS = \"<eos>\"\n",
    "MANS = \"<MANS>\"\n",
    "TRANSLATE = \"<TRANSLATE>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe25ea73-e9b9-4838-8773-b0b55c5cf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_articles():\n",
    "    mans_data = []\n",
    "    rus_data = []\n",
    "    for i in range(13, 25):\n",
    "        dt = pd.read_csv(f\"dataMans/LUIMA-SERIPOS_20{i}_RUS_MANS.csv\")\n",
    "        mans = dt.mans.tolist()\n",
    "        rus = dt.rus.tolist()\n",
    "        for i in range(len(rus)):\n",
    "            mans_data.append(MANS + mans[i].replace(\"\\n\", \" \").strip() + EOS)\n",
    "            rus_data.append(RUS + rus[i].replace(\"\\n\", \" \").strip() + EOS)\n",
    "\n",
    "    df_text = pd.read_csv(\"dataMans/READ_LITER.csv\")\n",
    "    mans = df_text.mans.tolist()\n",
    "    rus = df_text.rus.tolist()\n",
    "    for i in range(len(rus)):\n",
    "        mans_data.append(MANS + mans[i] + EOS)\n",
    "        rus_data.append(RUS + rus[i] + EOS)\n",
    "    return mans_data, rus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e243d50a-2deb-441e-9c6c-2c27f300f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_other(language_count=20000, count_mans=5):\n",
    "    data = []\n",
    "    random.seed(42)\n",
    "    df_komi = pd.read_csv(\"dataMans/komi-rus.csv\")\n",
    "    index = df_komi.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    komi = df_komi.loc[index[:language_count]][\"Коми язык\"].tolist()\n",
    "    rus = df_komi.loc[index[:language_count]][\"Русский язык\"].tolist()\n",
    "    for i in range(len(rus)):\n",
    "        data.append(RUS + rus[i] + TRANSLATE + KOMI + komi[i] + EOS)\n",
    "\n",
    "    komi = df_komi.loc[index[language_count:2 * language_count]][\"Коми язык\"].tolist()\n",
    "    rus = df_komi.loc[index[language_count:2 * language_count]][\"Русский язык\"].tolist()\n",
    "    for i in range(len(rus)):\n",
    "        data.append(KOMI + komi[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "    \n",
    "    df_udmurt = pd.read_csv(\"dataMans/udmurt-rus.csv\")\n",
    "    index = df_udmurt.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    udm = df_udmurt.loc[index[:language_count]].udm.tolist()\n",
    "    rus = df_udmurt.loc[index[:language_count]].ru.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(RUS + rus[i] + TRANSLATE + UDM + udm[i] + EOS)\n",
    "\n",
    "    udm = df_udmurt.loc[index[language_count:2 * language_count]].udm.tolist()\n",
    "    rus = df_udmurt.loc[index[language_count:2 * language_count]].ru.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(UDM + udm[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "\n",
    "    \n",
    "    df_mhr = pd.read_csv(\"dataMans/mhr-rus.csv\")\n",
    "    df_mhr = df_mhr.dropna(subset=[\"mhr\"])\n",
    "    index = df_mhr.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    mhr = df_mhr.loc[index[:language_count]].mhr.tolist()\n",
    "    rus = df_mhr.loc[index[:language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(RUS + rus[i] + TRANSLATE + MHR + mhr[i] + EOS)\n",
    "\n",
    "    mhr = df_mhr.loc[index[language_count:2 * language_count]].mhr.tolist()\n",
    "    rus = df_mhr.loc[index[language_count:2 * language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(MHR + mhr[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "\n",
    "    df_text = pd.read_csv(\"dataMans/Gospel_Mark_RUS_MANS.csv\")\n",
    "    index = df_text.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    mans = df_text.loc[index[:language_count]].mans.tolist()\n",
    "    rus = df_text.loc[index[:language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        for j in range(count_mans):\n",
    "            data.append(RUS + rus[i] + TRANSLATE + MANS + mans[i] + EOS)\n",
    "\n",
    "    udm = df_text.loc[index[language_count:2 * language_count]].mans.tolist()\n",
    "    rus = df_text.loc[index[language_count:2 * language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        for j in range(count_mans):\n",
    "            data.append(MANS + mans[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "\n",
    "    df_text = pd.read_csv(\"dataMans/Book_of_John_RUS_MANS.csv\")\n",
    "    index = df_text.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    mans = df_text.loc[index[:language_count]].mans.tolist()\n",
    "    rus = df_text.loc[index[:language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        for j in range(count_mans):\n",
    "            data.append(RUS + rus[i] + TRANSLATE + MANS + mans[i] + EOS)\n",
    "\n",
    "    udm = df_text.loc[index[language_count:2 * language_count]].mans.tolist()\n",
    "    rus = df_text.loc[index[language_count:2 * language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        for j in range(count_mans):\n",
    "            data.append(MANS + mans[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "\n",
    "    df_text = pd.read_csv(\"dataMans/Bible_UDM_RUS.csv\")\n",
    "    df_text = df_text.dropna(subset=[\"udm\"])\n",
    "    df_text = df_text.dropna(subset=[\"rus\"])\n",
    "    index = df_text.index.tolist()\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    udm = df_text.loc[index[:language_count]].udm.tolist()\n",
    "    rus = df_text.loc[index[:language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(RUS + rus[i] + TRANSLATE + UDM + udm[i] + EOS)\n",
    "\n",
    "    udm = df_text.loc[index[language_count:2 * language_count]].udm.tolist()\n",
    "    rus = df_text.loc[index[language_count:2 * language_count]].rus.tolist()\n",
    "\n",
    "    for i in range(len(rus)):\n",
    "        data.append(UDM + udm[i] + TRANSLATE + RUS + rus[i] + EOS)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82f0f5d6-403d-4679-bd59-0fe609da0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_examples = read_other()\n",
    "articles_mans, articles_rus = data_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ff25235-91fc-4aac-85ef-6dc33595db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.extend(translate_examples)\n",
    "data.extend(articles_rus)\n",
    "for elem in articles_mans:\n",
    "    data.append(elem)\n",
    "    data.append(elem)\n",
    "    data.append(elem)\n",
    "random.seed(7)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f28d87c-604a-46e5-afc5-118de9927b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168822"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2efe872b-bf9d-48d2-b2a4-f2cad13d59c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "with open(\"../train/spm_man.vocab\", \"r+\") as file1:\n",
    "    vocab = [elem.split(\"\\t\")[0] for elem in file1.read().split(\"\\n\")]\n",
    "\n",
    "RUS = \"<RUS>\"\n",
    "UDM = \"<UDM>\"\n",
    "KOMI = \"<KOMI>\"\n",
    "MHR = \"<MHR>\"\n",
    "MANS = \"<MANS>\"\n",
    "TRANSLATE = \"<TRANSLATE>\"\n",
    "COMPUTE = \"<COMPUTE>\"\n",
    "special_tokens_dict = {\"additional_special_tokens\": [RUS, UDM, KOMI, MHR, MANS]}\n",
    "# vocab.extend([RUS, UDM, KOMI, MHR, MANS])\n",
    "new_tokens = set(vocab) - set(tokenizer.vocab.keys())\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "700bf884-a194-410e-ba12-77cda5d0fcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RUS>А на заводе железобетонных изделий «ЗЖБИ Арктика» в городе предусмотрено создать линию для выпуска железобетонной продукции с учетом потребности рынка на северных, арктических территориях Коми и соседних регионов.<TRANSLATE><KOMI>А карса «ЗЖБИ Арктика» кӧрт бетона изделиеяс вӧчан заводын кӧсйӧны лэдзны кӧрт бетона продукция Комилӧн да орчча регионъяслӧн войвыв, арктика мутасъясын коланлун тӧд вылын кутӧмӧн.<eos>'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32433e49-b4b9-49e0-be7e-6c8f5f2a7abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MHR>Ой, Альбина ӱдырем толешыс.<RUS>Ой, Альбина, доченька, пришла.<eos>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[270792,\n",
       " 225199,\n",
       " 235269,\n",
       " 95895,\n",
       " 74667,\n",
       " 235248,\n",
       " 244672,\n",
       " 267554,\n",
       " 4550,\n",
       " 3572,\n",
       " 1480,\n",
       " 235426,\n",
       " 267517,\n",
       " 235265,\n",
       " 270789,\n",
       " 225199,\n",
       " 235269,\n",
       " 95895,\n",
       " 74667,\n",
       " 235269,\n",
       " 2879,\n",
       " 14312,\n",
       " 1176,\n",
       " 235269,\n",
       " 187709,\n",
       " 235265,\n",
       " 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = data[1][:100]\n",
    "print(sent)\n",
    "tokenizer.encode(sent, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c6c0224-e9ff-42b9-8f97-aea21b719291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[235248,\n",
       " 270789,\n",
       " 16339,\n",
       " 11147,\n",
       " 8211,\n",
       " 268685,\n",
       " 45150,\n",
       " 975,\n",
       " 260668,\n",
       " 235328,\n",
       " 235269,\n",
       " 2087,\n",
       " 11024,\n",
       " 235344,\n",
       " 269846,\n",
       " 235326,\n",
       " 10292,\n",
       " 1416,\n",
       " 1950,\n",
       " 269693,\n",
       " 262282,\n",
       " 256483,\n",
       " 235326,\n",
       " 235269,\n",
       " 18880,\n",
       " 2087,\n",
       " 78708,\n",
       " 26502,\n",
       " 262125,\n",
       " 2879,\n",
       " 174738,\n",
       " 235248,\n",
       " 264019,\n",
       " 2886,\n",
       " 235350,\n",
       " 78387,\n",
       " 235269,\n",
       " 18880,\n",
       " 2087,\n",
       " 33629,\n",
       " 235402,\n",
       " 256735,\n",
       " 20668,\n",
       " 2879,\n",
       " 174738,\n",
       " 21377,\n",
       " 1215,\n",
       " 40498,\n",
       " 4501,\n",
       " 235265,\n",
       " 235248,\n",
       " 270790,\n",
       " 260668,\n",
       " 93526,\n",
       " 138523,\n",
       " 264752,\n",
       " 235269,\n",
       " 256483,\n",
       " 258430,\n",
       " 261697,\n",
       " 138523,\n",
       " 258710,\n",
       " 1157,\n",
       " 108,\n",
       " 267548,\n",
       " 2886,\n",
       " 235350,\n",
       " 263893,\n",
       " 264794,\n",
       " 261831,\n",
       " 235269,\n",
       " 108,\n",
       " 10258,\n",
       " 265170,\n",
       " 264756,\n",
       " 263026,\n",
       " 265824,\n",
       " 269420,\n",
       " 235320,\n",
       " 264794,\n",
       " 261741,\n",
       " 235265,\n",
       " 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(data[0], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e927a59-4afd-4a40-bbb3-1f4d4587db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = {}\n",
    "dt['train'] = data[:int(len(data) * 0.98)]\n",
    "dt['test'] = data[int(len(data) * 0.98):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67195ad6-612e-4dc3-ac53-a2d71e0d19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"data.json\", \"w\")  \n",
    "    \n",
    "json.dump(dt, out_file, indent = 6)  \n",
    "    \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5048b30-3d35-411f-b837-9577d5d61c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165445, 3377)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt['train']), len(dt['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c02065-c5b5-4b7f-a528-0435153181b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
